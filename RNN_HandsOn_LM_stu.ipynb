{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_HandsOn_LM_stu.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunjin-C/hyunjin-C/blob/main/RNN_HandsOn_LM_stu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5QGNiftI6cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d560956-7807-403a-b385-9c5ed91e43bf"
      },
      "source": [
        "#필요한 라이브러리들 로딩하기\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "#데이터 다운받기 (세익스피어 소설 데이터)\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "# 읽은 다음 파이썬 2와 호환되도록 디코딩합니다.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "#샘플 출력해보기\n",
        "print(text[:20], '\\n')\n",
        "# 텍스트의 길이는 그 안에 있는 문자의 수입니다.\n",
        "print ('텍스트의 길이: {}자'.format(len(text)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "First Citizen:\n",
            "Befor \n",
            "\n",
            "텍스트의 길이: 1115394자\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuoWrd4MbXNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc611a9a-8b0e-46bd-f4f1-321eb5fa0b39"
      },
      "source": [
        "# 파일의 고유 문자수를 출력 및 고유 문자로 단어장 만들기\n",
        "vocab = sorted(set(text))\n",
        "print ('고유 문자수 {}개'.format(len(vocab)))\n",
        "\n",
        "# 위에서 만든 단어장을 이용해서 고유 문자에서 인덱스로 매핑 생성\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "#문자 -> 인덱스 매칭 샘플 출력해보기\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')\n",
        "\n",
        "# 텍스트에서 처음 13개의 문자가 숫자로 어떻게 매핑되었는지를 보여줍니다\n",
        "print ('{} ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > {}'.format(repr(text[:13]), text_as_int[:13]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고유 문자수 65개\n",
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n",
            "'First Citizen' ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-nZEOmbXeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e76f4cc-2bf3-42af-8b4d-bcae89b2156a"
      },
      "source": [
        "# 단일 입력에 대해 원하는 문장의 최대 길이\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text) / seq_length\n",
        "\n",
        "# 훈련 샘플/타깃 만들고 샘플 출력 해보기\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX5A5ePNbXtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cbb287-98c2-4317-8026-34cfc3d2badd"
      },
      "source": [
        "#seq_length+1길이만큼을 하나의 배치 단위로 데이터 만들기\n",
        "#Input = sequence[:-1]\n",
        "#Target = sequence[1:]\n",
        "#Hello -> Input: Hell, Target: ello\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "#첫번째 다섯개 배치에 대해서 출력 해보기\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n",
        "\n",
        "#입력데이터랑 타겟데이터 만들기\n",
        "'''\n",
        "Hello \n",
        "Hell -> ello\n",
        "예제\n",
        "전체 문장: First Citizen\n",
        "입력: First Citize\n",
        "타겟: irst Citizen\n",
        "'''\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('입력 데이터: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('타깃 데이터: ', repr(''.join(idx2char[target_example.numpy()])))\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"{:4d}단계\".format(i))\n",
        "    print(\"  입력: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  예상 출력: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n",
            "입력 데이터:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "타깃 데이터:  'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "   0단계\n",
            "  입력: 18 ('F')\n",
            "  예상 출력: 47 ('i')\n",
            "   1단계\n",
            "  입력: 47 ('i')\n",
            "  예상 출력: 56 ('r')\n",
            "   2단계\n",
            "  입력: 56 ('r')\n",
            "  예상 출력: 57 ('s')\n",
            "   3단계\n",
            "  입력: 57 ('s')\n",
            "  예상 출력: 58 ('t')\n",
            "   4단계\n",
            "  입력: 58 ('t')\n",
            "  예상 출력: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtr-Lj4HbX0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e866396a-438f-4bcf-ecc0-1c56639d4d5d"
      },
      "source": [
        "# 학습과 관련된 Hyper parameter들 정의 및 데이터 셔플 진행\n",
        "# 배치 크기\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 단어장의 크기\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 임베딩 차원\n",
        "embedding_dim = 256\n",
        "\n",
        "# RNN 유닛(unit) 개수\n",
        "rnn_units = 1024\n",
        "\n",
        "# 데이터셋을 섞을 버퍼 크기.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O4RYGTtbYQ3"
      },
      "source": [
        "# 모델 구조 정의 및 모델 빌드\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    ##tf.keras.layers.Embedding(input_dim, output_dim,...)\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size) #모델의 출력값은 단어장의 인덱스를 One-Hot형태로 출력하도록 학습할것이 때문에 출력 Dimension은 단어장의 크기로 설정.\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlpJdVn2bYWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba63eee-873b-4be8-b5db-af1810bf0a39"
      },
      "source": [
        "#데이터 샘플의 Dimension출력해보기\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (배치 크기, 시퀀스 길이, 어휘 사전 크기)\")\n",
        "\n",
        "#모델 구조 출력\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (배치 크기, 시퀀스 길이, 어휘 사전 크기)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyjL6bB0bYsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e4cbf8-3e31-4294-96a7-bbcd493638f7"
      },
      "source": [
        "#랜덤하게 예측 했을 때의 결과값을 한 번 출력해보기\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38, 17,  2, 61, 54, 27, 26, 20, 14, 12, 16, 37, 41, 51, 31, 22, 24,\n",
              "       16,  9, 42, 24, 30, 62, 19, 27, 33,  0,  3, 28,  7, 45, 46, 54, 50,\n",
              "       21, 27, 37, 58, 11, 53, 19, 60, 19, 43, 17, 17,  5, 28, 35,  5, 11,\n",
              "       61, 32, 62, 39, 38, 19, 33, 58, 62, 28, 42, 32, 13, 17, 27, 20,  1,\n",
              "       33,  6, 11, 16, 13, 27, 18, 22, 19, 57, 49,  9, 47, 25, 17, 35,  4,\n",
              "        1, 14, 45, 22, 30,  2,  8, 13, 25, 16, 21, 62, 18, 21, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulwM9dzbbYrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5059dd-942c-4e4a-c570-a172fbcd6334"
      },
      "source": [
        "print(\"입력: \\n\", \"\".join(idx2char[input_example_batch[0]]))\n",
        "print()\n",
        "print(\"예측된 다음 문자: \\n\", \"\".join(idx2char[sampled_indices ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력: \n",
            "  set of beads,\n",
            "My gorgeous palace for a hermitage,\n",
            "My gay apparel for an almsman's gown,\n",
            "My figured \n",
            "\n",
            "예측된 다음 문자: \n",
            " ZE!wpONHB?DYcmSJLD3dLRxGOU\n",
            "$P-ghplIOYt;oGvGeEE'PW';wTxaZGUtxPdTAEOH U,;DAOFJGsk3iMEW& BgJR!.AMDIxFID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKy5NB-hbYQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cff909-3c2d-43a3-e9fd-8f060e66587e"
      },
      "source": [
        "#loss정의 및 모델 컴파일\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"예측 배열 크기(shape): \", example_batch_predictions.shape, \" # (배치 크기, 시퀀스 길이, 어휘 사전 크기\")\n",
        "print(\"스칼라 손실:          \", example_batch_loss.numpy().mean())\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 배열 크기(shape):  (64, 100, 65)  # (배치 크기, 시퀀스 길이, 어휘 사전 크기\n",
            "스칼라 손실:           4.1739306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmaOBYW0bXys"
      },
      "source": [
        "# 체크포인트가 저장될 디렉토리\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# 체크포인트 파일 이름\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr0McUmabXsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede54e1f-2844-442f-a78e-292c2262f622"
      },
      "source": [
        "#모델 학습 진행\n",
        "EPOCHS=10\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 12s 53ms/step - loss: 2.6639\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.9454\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.6791\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.5328\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.4457\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3880\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3425\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3044\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.2694\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.2362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQBHkAZNQHvA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b24b2c88-1d1d-40d8-d77f-93f42b9574f7"
      },
      "source": [
        "#마지막 체크포인트 확인\n",
        "tf.train.latest_checkpoint(checkpoint_dir)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pudhMkwZK5Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936fdf9a-5b62-43ea-c254-2d6424c77197"
      },
      "source": [
        "#문장 생성을 위해서 모델의 입력 베치 사이즈를 수정하고 학습된 모델의 Weight을 읽어오기\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6McGNEcTK7N1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05MAsh-xg4VV"
      },
      "source": [
        "#언어 모델을 이용해서 입력된 단어들을 이용하여 나머지 문장들을 생성하는 함수 정의\n",
        "def generate_text(model, start_string):\n",
        "  # 평가 단계 (학습된 모델을 사용하여 텍스트 생성)\n",
        "\n",
        "  # 생성할 문자의 수\n",
        "  num_generate = 1000\n",
        "\n",
        "  # 시작 문자열을 숫자로 변환(벡터화)\n",
        "  input_eval = [char2idx[word] for word in start_string] ##코드 작성 필요 hint: char2idx[]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # 결과를 저장할 빈 문자열\n",
        "  text_generated = []\n",
        "\n",
        "  # 온도가 낮으면 더 예측 가능한 텍스트가 됩니다.\n",
        "  # 온도가 높으면 더 의외의 텍스트가 됩니다.\n",
        "  # 최적의 세팅을 찾기 위한 실험\n",
        "  temperature = 1.0\n",
        "\n",
        "  # 여기에서 배치 크기 == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # 배치 차원 제거\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # 범주형 분포를 사용하여 모델에서 리턴한 단어 예측\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[0,0].numpy() ##코드 작성 필요 -> predictions 분포에서 랜덤하게 샘플링하는 코드 작성 Hint: tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "      \n",
        "      # 예측된 단어를 다음 입력으로 모델에 전달\n",
        "      # 이전 은닉 상태와 함께\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIR98PWJg4Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b6a21b-adba-4323-86dc-62552b4fedb9"
      },
      "source": [
        "# 문장 생성 해보기\n",
        "print(generate_text(model, start_string=u\"ROMEO: \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: Kate, for't:\n",
            "I thought, blows, what mine only, in arms.\n",
            "\n",
            "KING EDWARD IV:\n",
            "You are donng, sir, not op done your accusONRK:\n",
            "Thou hast our senseless my last,\n",
            "I do lighterous after Buckingham,\n",
            "As ere thou, therefore in all this mercy, brother Marbius,\n",
            "Who hastesh sin a poxt privat by\n",
            "That drink no brealth. You sie is came from grief man's for.\n",
            "\n",
            "KATHARINA:\n",
            "What, his rest th Ky heart's countenance,\n",
            "Thou heard'st, I pray you to the Taril: I wonder raise you: may, thou shalt not.\n",
            "\n",
            "Nurse:\n",
            "Most what they set me; this prince thou haste.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Thy die of sweet lo, she's bagning but our company\n",
            "And sayd is satch'd: if you were eyed uland,\n",
            "Now come to make me breathed at my cold confised more were yet, an old heart,\n",
            "Who lack as more before for I know, O, he\n",
            "would his friend will kill revenge my his arm to end with solemn rawed of thine.\n",
            "\n",
            "MISTERSER:\n",
            "The messings stalls\n",
            "The lady-sidow now of this old creataron:\n",
            "What it will be up the unkern mourth both of this,\n",
            "Which I wound her rark\n",
            "Of this\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}